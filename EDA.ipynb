{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7TzfgHHd6iP"
      },
      "source": [
        "#pip install py_thesaurus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHfll_CUf2UT"
      },
      "source": [
        "import os\n",
        "import spacy\n",
        "import random\n",
        "import nltk \n",
        "from nltk.corpus import wordnet \n",
        "import en_core_web_sm\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jukDyj40STQC"
      },
      "source": [
        "##Synonym Replacement\n",
        "\n",
        "Synonym replacement is a technique in which we replace a word by one of its synonyms. \n",
        "\n",
        "The 'syn_replacement' function uses NLTK library and checks the level of similarity (value between 0..1) between a word and its synonyms. Selection of a new word would be done across maximum similarity value(s).\n",
        "\n",
        "2 Types of POS (Part of Speech) are used: Noun and Verb. POS takes in input as ’n’ or ‘v’ where n stands for noun and v for verbs. Noun and Verb are sorted out using Spacy. If the output of ‘wup_similarity’ is NULL then it passes on to Spacy for comparison of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2SXi8EpgIz7"
      },
      "source": [
        "\n",
        "def syn_replacement(word,synonyms,POS):\n",
        "    \"\"\"\n",
        "    - Main aim of this function is to return the most similar word to the given input word.\n",
        "    - Arguments:\n",
        "    - word: specific word as a string (present in input data)\n",
        "    - synonyms: List of all synonyms of a word.\n",
        "    - (POS) Part of Speech: Noun or Verb.\n",
        "    \"\"\"\n",
        "    max_temp = -1\n",
        "    flag = 0\n",
        "    for i in synonyms:\n",
        "        try:\n",
        "            # n denotes noun and v denotes verb\n",
        "            w1 = wordnet.synset(word+'.'+POS+'.01') \n",
        "            w2 = wordnet.synset(i+'.'+POS+'.01')\n",
        "            # check for the highest synomym similarity\n",
        "            if(max_temp<w1.wup_similarity(w2)):\n",
        "                max_temp=w1.wup_similarity(w2)\n",
        "                temp_name = i\n",
        "                flag =1\n",
        "        except:\n",
        "            f = 0\n",
        "            \n",
        "    if flag == 0: # If the output of wup_similarity is NULL then use Spacy for comparison of words\n",
        "        max1 = -1.\n",
        "        value = ' '\n",
        "        nlp = en_core_web_sm.load()\n",
        "        for i in synonyms:\n",
        "            j=i.replace(' ', '')\n",
        "            tokens = nlp(u''+j)\n",
        "            token_main = nlp(u''+word)\n",
        "            for token1 in token_main:\n",
        "                if max1<float(token1.similarity(tokens)):\n",
        "                    max1 = token1.similarity(tokens)\n",
        "                    value = i\n",
        "        max1 = -1.\n",
        "        return value \n",
        "    else:\n",
        "        return temp_name"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnDQfBLKUwIY"
      },
      "source": [
        "###I use WordNet, a large linguistic database, to identify relevant synonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHI7GPmBn3Bw",
        "outputId": "d7d7e00c-b5b4-435b-c2e7-6d6090cd7574"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def get_synonyms(word):\n",
        "    \"\"\"\n",
        "    Get synonyms of a word\n",
        "    \"\"\"\n",
        "    synonyms = set()\n",
        "    \n",
        "    # Synset from NLTK to look up words in WordNet\n",
        "    # In WordNet, similar words are grouped into a set known as a Synset (short for Synonym-set)\n",
        "    # The words in a Synset are known as Lemmas.\n",
        "    for syn in wordnet.synsets(word): \n",
        "        for l in syn.lemmas(): \n",
        "            synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
        "            synonyms.add(synonym) \n",
        "    \n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    \n",
        "    return list(synonyms)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDeGpmikVZkT"
      },
      "source": [
        "The main code steps: \n",
        "- Read text file from Google Colab drive folder and create a list of Text Files\n",
        "- For each text file and each line in the text file, process with the following steps:\n",
        "\n",
        "\n",
        "- Split the line (sentence) into words\n",
        "- Count the total number of unique words and make a list of unique words\n",
        "- Remove 1 and 2 letters word & numbers\n",
        "- Make a list of Noun and Verb using spacy from the above word list\n",
        "- Loop through all words\n",
        "- Find out all the synonyms using the ‘get synonyms’ function and make a list\n",
        "- Checking If a selected word is Noun or Verb and then passing to ‘syn_replacement’ function\n",
        "- Replacing the word with the new most similar word\n",
        "- Storing the new sentences in output file in Google Colab drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGbaEDAVgdUj",
        "outputId": "8f287fcf-defc-4120-99b2-b0330cbd03c8"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "  \n",
        "# Read text file from Google Colab drive folder and create a list of Text Files \n",
        "all_files = os.listdir(\"/content/drive/MyDrive/data/\")\n",
        "txt_files = filter(lambda x: x[-4:] == '.txt', all_files)\n",
        "\n",
        "# For each text file and each line in the text file, process with the following steps\n",
        "\n",
        "#...per file\n",
        "for i in txt_files:\n",
        "    textfile = i\n",
        "    print(\"Input File: \"+ textfile)\n",
        "    print(\" \")\n",
        "    path = '/content/drive/MyDrive/data/'+textfile\n",
        "    exists = os.path.isfile(path)\n",
        "    if exists: \n",
        "        file_open = open(path,\"r\")\n",
        "        text_lines = file_open.readlines()\n",
        "        #...per line in a file\n",
        "        for text in text_lines:\n",
        "          output_text = text\n",
        "          print(\"Sentence: \"+text)\n",
        "          # Split the line (sentence) into words\n",
        "          words = text.split()\n",
        "\n",
        "          # Count the total number of unique words and make a list of unique words\n",
        "          counts = {}\n",
        "          for word in words:\n",
        "              if word not in counts:\n",
        "                  counts[word] = 0\n",
        "              counts[word] += 1\n",
        "          \n",
        "          # Remove 1 and 2 letters word & numbers.\n",
        "          one_word = []\n",
        "          for key, value in counts.items():\n",
        "              if value == 1 and key.isalpha() and len(key)>2:\n",
        "                  one_word.append(key)\n",
        "          \n",
        "          # Make a list of Noun and Verb using spacy from the above word list\n",
        "          noun = []\n",
        "          verb = []\n",
        "          # nlp refers to the language model loaded by en_core_web_sm.\n",
        "          nlp = spacy.load('en_core_web_sm')\n",
        "          doc = nlp(u''+' '.join(one_word))\n",
        "          for token in doc:\n",
        "              if  token.pos_ == 'VERB':\n",
        "                  verb.append(token.text)\n",
        "              if  token.pos_ == 'NOUN':\n",
        "                  noun.append(token.text)\n",
        "              \n",
        "          all_main =verb + noun\n",
        "          len_all = len(noun)+len(verb)\n",
        "          f_output = open('/content/drive/MyDrive/data/'+'output_'+textfile+'file', \"a\")\n",
        "          for i in range(len_all):\n",
        "            word_str = all_main[i]\n",
        "            \n",
        "            # Find out all the synonyms of a word\n",
        "            synonyms = get_synonyms(word_str)\n",
        "            \n",
        "            # Replacing the word with the new most similar words\n",
        "            if i<len(verb):\n",
        "                change_word=syn_replacement(word_str,synonyms,'v')\n",
        "                try:\n",
        "                    search_word = re.search(r'\\b('+word_str+r')\\b', output_text)\n",
        "                    Loc = search_word.start()\n",
        "                    output_text = output_text[:int(Loc)] + change_word + output_text[int(Loc) + len(word_str):]\n",
        "                except:\n",
        "                    f=0\n",
        "\n",
        "            else:\n",
        "                change_word=syn_replacement(word_str,synonyms,'n')\n",
        "                try:\n",
        "                    search_word = re.search(r'\\b('+word_str+r')\\b', output_text)\n",
        "                    Loc = search_word.start()\n",
        "                    output_text = output_text[:int(Loc)] + change_word + output_text[int(Loc) + len(word_str):]\n",
        "                except:\n",
        "                    f=0\n",
        "            \n",
        "            # Storing the new sentences in output file\n",
        "            f_output.write(str(output_text))\n",
        "            print(output_text)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input File: sample2.txt\n",
            " \n",
            "Sentence: data can leave customer premises\n",
            "\n",
            "data displace leave customer premises\n",
            "\n",
            "data displace lead customer premises\n",
            "\n",
            "information displace lead customer premises\n",
            "\n",
            "information displace lead client premises\n",
            "\n",
            "information displace lead client premiss\n",
            "\n",
            "Sentence: data has to stay in customer premises\n",
            "\n",
            "data has to remain in customer premises\n",
            "\n",
            "information has to remain in customer premises\n",
            "\n",
            "information has to remain in client premises\n",
            "\n",
            "information has to remain in client premiss\n",
            "\n",
            "Sentence: It is not allowed to export the data\n",
            "\n",
            "It is not let to export the data\n",
            "\n",
            "It is not let to exportation the data\n",
            "\n",
            "It is not let to exportation the information\n",
            "\n",
            "Sentence: exported data should be first be encrypted\n",
            "\n",
            "export data should be first be encrypted\n",
            "\n",
            "export data   be first be encrypted\n",
            "\n",
            "export data   be first be write in code\n",
            "\n",
            "export information   be first be write in code\n",
            "\n",
            "Sentence: exported data should be encrypted at rest and in transit\n",
            "\n",
            "export data should be encrypted at rest and in transit\n",
            "\n",
            "export data   be encrypted at rest and in transit\n",
            "\n",
            "export data   be write in code at rest and in transit\n",
            "\n",
            "export information   be write in code at rest and in transit\n",
            "\n",
            "export information   be write in code at remainder and in transit\n",
            "\n",
            "export information   be write in code at remainder and in theodolite\n",
            "\n",
            "Sentence: It is allowed to export encrypted data outisde on the customer premises\n",
            "\n",
            "It is let to export encrypted data outisde on the customer premises\n",
            "\n",
            "It is let to export write in code data outisde on the customer premises\n",
            "\n",
            "It is let to exportation write in code data outisde on the customer premises\n",
            "\n",
            "It is let to exportation write in code information outisde on the customer premises\n",
            "\n",
            "It is let to exportation write in code information outisde on the client premises\n",
            "\n",
            "It is let to exportation write in code information outisde on the client premiss\n",
            "\n",
            "Sentence: All data has to be stored in the same country as the operator network\n",
            "\n",
            "All data has to be lay in in the same country as the operator network\n",
            "\n",
            "All information has to be lay in in the same country as the operator network\n",
            "\n",
            "All information has to be lay in in the same nation as the operator network\n",
            "\n",
            "All information has to be lay in in the same nation as the manipulator network\n",
            "\n",
            "All information has to be lay in in the same nation as the manipulator meshing\n",
            "\n",
            "Sentence: data can be stored in Ericsson premises but not in public cloud\n",
            "\n",
            "data displace be stored in Ericsson premises but not in public cloud\n",
            "\n",
            "data displace be lay in in Ericsson premises but not in public cloud\n",
            "\n",
            "information displace be lay in in Ericsson premises but not in public cloud\n",
            "\n",
            "information displace be lay in in Ericsson premiss but not in public cloud\n",
            "\n",
            "information displace be lay in in Ericsson premiss but not in public fog\n",
            "\n",
            "Sentence: data cannot be stored in public cloud\n",
            "\n",
            "data cannot be stored in public cloud\n",
            "\n",
            "data cannot be lay in in public cloud\n",
            "\n",
            "information cannot be lay in in public cloud\n",
            "\n",
            "information cannot be lay in in public fog\n",
            "\n",
            "Sentence: the customer wants its data to stay in its premises\n",
            "the customer need its data to stay in its premises\n",
            "the customer need its data to remain in its premises\n",
            "the client need its data to remain in its premises\n",
            "the client need its information to remain in its premises\n",
            "the client need its information to remain in its premiss\n",
            "Input File: output_sample2.txt\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}